# Local AI Agent using RAG

A local AI agent that answers questions using relevant information retrieved from a pizza restaurant's reviews. Built with **LangChain** and **Ollama LLaMA 3.2**, it combines **Retrieval-Augmented Generation (RAG)** with a chat interface for context-aware responses.

---

## Features
- Retrieve relevant reviews based on user queries.
- Generate AI-powered answers using LLaMA 3.2.
- Local execution using Ollama, no cloud required.
- Interactive chat loop for continuous Q&A.

---

## Requirements
- Python 3.10+
- Ollama installed and configured
- Required Python packages:
```bash
pip install langchain ollama
